// -*- c++ -*-
//
// michael a.g. aïvázis <michael.aivazis@para-sim.com>
// (c) 1998-2023 all rights reserved


// code guard
#if !defined(pyre_cuda_memory_Managed_icc)
#error this file contains implementation details for pyre::cuda::memory::Managed
#else


// metamethods
// constructor
template <class T, bool isConst>
pyre::cuda::memory::Managed<T, isConst>::
Managed(cell_count_type cells) :
    // the cuda {malloc} api is not RAII friendly, so we initialize with a {nullptr} and
    // replace it with the actual allocation
    _data{ nullptr },
    _cells{ cells }
{
    // grab a spot
    pointer spot = nullptr;
    // compute the memory footprint
    auto footprint = cells * sizeof(value_type);
    // allocate memory
    auto status = cudaMallocManaged(&spot, footprint);
    // if something went wrong
    if (status != cudaSuccess) {
        // make a channel
        pyre::journal::error_t error("pyre.cuda");
        // complain
        error
            << "while allocating " << footprint << " bytes of device memory: "
            << pyre::journal::newline
            << cudaGetErrorName(status) << " (" << status << ")"
            << pyre::journal::endl(__HERE__);
        // and bail
        throw std::bad_alloc();
    }

    // all went well
    pyre::journal::debug_t channel("pyre.cuda.managed_t");
    // so let me know
    channel
        << "allocated " << footprint << " bytes at " << (void *)spot
        << pyre::journal::endl(__HERE__);

    // zero out the memory
    status = cudaMemset(spot, 0, footprint);
    // if something went wrong
    if (status != cudaSuccess) {
        // get the error description
        std::string description = cudaGetErrorName(status);
        // make a channel
        pyre::journal::error_t error("pyre.cuda");
        // complain
        error
            << "while initializing " << footprint
            << " bytes of device memory for the offset field: "
            << description << " (" << status << ")"
            << pyre::journal::endl(__HERE__);
        // and bail
        throw std::runtime_error(description);
    }

    // if all went well, make a deleter for CUDA allocated memory
    auto destructor = [footprint](auto ptr) {
        // attempt to free the block of memory
        auto status = cudaFree(ptr);
        // if something went wrong
        if (status != cudaSuccess) {
            // make a channel
            pyre::journal::error_t error("pyre.cuda");
            // complain
            error
                << "while deallocating " << footprint << " bytes of device memory: "
                << pyre::journal::newline
                << cudaGetErrorName(status) << " (" << status << ")"
                << pyre::journal::endl(__HERE__);
        }
        // all went well
        pyre::journal::debug_t channel("pyre.cuda.managed_t");
        // so let me know
        channel
            << "deallocated " << footprint << " bytes starting at "
            << (void *) ptr << " on the device"
            << pyre::journal::endl(__HERE__);
        // all done
        return;
    };

    // replace the {nullptr} with the new block and register the deallocator
    _data.reset(spot, destructor);
}


template <class T, bool isConst>
pyre::cuda::memory::Managed<T, isConst>::
Managed(handle_type handle, cell_count_type cells) :
    _data{ handle },
    _cells{ cells }
{}

// interface
// get the number of cells in the block
template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
cells() const -> cell_count_type
{
    // easy
    return _cells;
}


// get the memory footprint of the block
template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
bytes() const -> size_type
{
    // scale the number of cells by the cell size
    return cells() * sizeof(value_type);
}


// access to the data pointer
template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
data() const -> pointer
{
    // return the raw data pointer
    return _data.get();
}


// get the shared pointer
template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
handle() const -> handle_type
{
    // easy
    return _data;
}


// iterator support
template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
begin() const -> pointer
{
    // the beginning of the block
    return data();
}


template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
end() const -> pointer
{
    // one past the last cell in the block
    return data() + cells();
}


// data access
template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
at(size_type pos) const -> reference
{
    // if the request is out of bounds
    if (pos >= cells()) {
        // make a channel
        pyre::journal::firewall_t channel("pyre.memory.bounds");
        // and complain
        channel
            << "out of bounds access:" << pyre::journal::newline
            << "  index " << pos << " must be less than " << cells() << pyre::journal::newline
            << "  in pyre::cuda::memory::managed_t::operator[]" << pyre::journal::newline
            << "  with a block on the heap at " << data()
            << pyre::journal::endl(__HERE__);
        // unreachable, unless the user has marked this error as non-fatal
        // clamp {pos} to the last element in the block
        pos = cells() - 1;
    }

    // return a reference to the cell at {pos}
    return data()[pos];
}


template <class T, bool isConst>
auto
pyre::cuda::memory::Managed<T, isConst>::
operator [] (size_type pos) const -> reference
{
    // return a reference to the cell at {pos}
    return data()[pos];
}


#endif

// end of file
